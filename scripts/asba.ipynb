{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/viltet/thesis/blob/main/scripts/asba.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install necessary libraries if they are not already in the Colab environment\n",
        "!pip install pandas tqdm torch transformers scikit-learn spacy -q\n",
        "!python -m spacy download en_core_web_sm -q\n",
        "\n",
        "# Mount Google Drive to access your files\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MGIEylWhcddp",
        "outputId": "722ba5d8-8263-41cd-a118-f33e98138c82"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/12.8 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.1/12.8 MB\u001b[0m \u001b[31m184.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m237.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m237.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m108.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "source": [
        "#@title 1. Loading libraries\n",
        "\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "from tqdm.auto import tqdm # Progress bar for loops\n",
        "import torch # PyTorch for deep learning models\n",
        "import re # Regular expressions for text processing\n",
        "import gc # Garbage collector for memory management\n",
        "import spacy # For sentence splitting\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification # Hugging Face Transformers\n",
        "import os # For directory creation\n",
        "\n",
        "# Display options for pandas\n",
        "pd.set_option('display.max_colwidth', 200) # Show more text in DataFrame cells\n",
        "print(\"Libraries imported.\")"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n0HDMpJXgCMx",
        "outputId": "bc4d5640-54e9-41e5-8e81-66dbf1ecba74"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Libraries imported.\n"
          ]
        }
      ]
    },
    {
      "source": [
        "#@title 2. Configuration Parameters & Path Setup\n",
        "\n",
        "# --- Main Configuration ---\n",
        "ASSISTANT_NAMES = [\"alexa\", \"google\"] # Datasets to process\n",
        "MODEL_DEBERTA_ABSA = 'yangheng/deberta-v3-base-absa-v1.1' # Chosen ABSA model\n",
        "MAX_SEQ_LENGTH = 512 # Max sequence length for the model\n",
        "PROCESS_ALL_REVIEWS = True # Set to True for full run, False to use NUM_REVIEWS_TO_PROCESS_DEBUG\n",
        "NUM_REVIEWS_TO_PROCESS_DEBUG = 100 # Number of reviews to process if PROCESS_ALL_REVIEWS is False (for quick debugging)\n",
        "\n",
        "# --- Google Drive Path Setup ---\n",
        "# IMPORTANT: This path should point to YOUR main thesis folder on Google Drive.\n",
        "# This folder should contain a 'results' subfolder with your input CSVs.\n",
        "# Based on your confirmation, it's \"MyThesisProject\" in your MyDrive.\n",
        "THESIS_ROOT_DRIVE = Path(\"/content/drive/MyDrive/MyThesisProject/\")\n",
        "\n",
        "# --- Derived Paths ---\n",
        "# The script expects your input CSVs (e.g., alexa_with_topics.csv)\n",
        "# to be inside a 'results' subfolder within your THESIS_ROOT_DRIVE.\n",
        "input_dir = THESIS_ROOT_DRIVE / \"results\"\n",
        "output_dir = THESIS_ROOT_DRIVE / \"results\" / \"absa_full_results_colab\" # Separate output for Colab runs\n",
        "output_dir.mkdir(parents=True, exist_ok=True) # Create output directory if it doesn't exist\n",
        "\n",
        "print(f\"THESIS_ROOT on Drive set to: {THESIS_ROOT_DRIVE.resolve()}\")\n",
        "print(f\"Expecting input CSVs in: {input_dir.resolve()}\")\n",
        "print(f\"Output directory for ABSA results: {output_dir.resolve()}\")\n",
        "\n",
        "# --- Device Setup (GPU/CPU) ---\n",
        "if torch.cuda.is_available():\n",
        "    DEVICE = torch.device(\"cuda\")\n",
        "    DEVICE_NAME_INFO = torch.cuda.get_device_name(0)\n",
        "    print(f\"Using GPU: {DEVICE_NAME_INFO}\")\n",
        "else:\n",
        "    DEVICE = torch.device(\"cpu\")\n",
        "    print(\"Using CPU. Processing will be slower. Ensure GPU is enabled in Colab Runtime settings.\")\n",
        "\n",
        "# --- Aspect Taxonomy (Copy from your previous script) ---\n",
        "taxonomy = {\n",
        "    \"Functionality & Performance\": [\n",
        "        \"command\", \"task\", \"function\", \"request\", \"execute\", \"perform\", \"play\", \"control\",\n",
        "        \"music\", \"timer\", \"alarm\", \"respond\", \"slow\", \"fast\", \"quick\", \"accurate\", \"ability\",\n",
        "        \"capability\", \"feature\", \"work\", \"operation\", \"answer\", \"weather\", \"news\", \"skill\",\n",
        "        \"search\", \"query\", \"song\", \"playlist\", \"speed\", \"performance\", \"reliable\", \"inconsistent\",\n",
        "        \"consistent\", \"accomplish\", \"smart\", \"intelligence\", \"stupid\", \"dumb\", \"basic\"\n",
        "    ],\n",
        "    \"Voice Recognition\": [\n",
        "        \"hear\", \"listen\", \"recognize\", \"understanding\", \"mic\", \"voice\", \"accent\", \"speech\",\n",
        "        \"microphone\", \"wake\", \"alexa\", \"hey google\", \"ok google\", \"command\", \"activation\",\n",
        "        \"trigger\", \"phrase\", \"call\", \"name\", \"hear me\", \"misheard\", \"mishear\", \"understand\",\n",
        "        \"detection\", \"sensitivity\", \"accent\", \"pronunciation\", \"dialect\", \"language\", \"recognition\"\n",
        "    ],\n",
        "    \"Knowledge Base\": [\n",
        "        \"answer\", \"knowledge\", \"info\", \"response\", \"fact\", \"question\", \"data\", \"correct\",\n",
        "        \"wrong\", \"information\", \"knowing\", \"research\", \"source\", \"accurate\", \"inaccurate\",\n",
        "        \"encyclopedia\", \"intelligence\", \"smart\", \"learn\", \"education\", \"informed\", \"wisdom\",\n",
        "        \"trivia\", \"facts\", \"content\", \"query\", \"request\", \"answer\", \"respond\"\n",
        "    ],\n",
        "    \"Integration & Ecosystem\": [\n",
        "        \"integrate\", \"connect\", \"compatible\", \"device\", \"home\", \"nest\", \"smart home\", \"ecosystem\",\n",
        "        \"philips\", \"hue\", \"lights\", \"thermostat\", \"tv\", \"television\", \"speaker\", \"app\", \"phone\",\n",
        "        \"smartphone\", \"skill\", \"third-party\", \"partner\", \"service\", \"platform\", \"sync\",\n",
        "        \"connection\", \"pair\", \"bluetooth\", \"wifi\", \"wireless\", \"smart\", \"bulb\", \"plug\", \"switch\",\n",
        "        \"camera\", \"doorbell\", \"lock\", \"appliance\", \"interoperability\", \"echo\", \"home mini\"\n",
        "    ],\n",
        "    \"Usability & Interface\": [\n",
        "        \"setup\", \"interface\", \"easy\", \"use\", \"design\", \"confusing\", \"intuitive\", \"simple\",\n",
        "        \"complicated\", \"difficult\", \"user-friendly\", \"accessibility\", \"accessible\", \"learn\",\n",
        "        \"instructions\", \"guide\", \"tutorial\", \"help\", \"clear\", \"straightforward\", \"configuration\",\n",
        "        \"settings\", \"customize\", \"personalize\", \"navigate\", \"interaction\", \"command structure\"\n",
        "    ],\n",
        "    \"Privacy & Security\": [\n",
        "        \"privacy\", \"data\", \"listening\", \"security\", \"surveillance\", \"record\", \"spy\", \"collect\",\n",
        "        \"tracking\", \"concern\", \"worry\", \"safe\", \"unsafe\", \"breach\", \"leak\", \"consent\", \"permission\",\n",
        "        \"trust\", \"trustworthy\", \"creepy\", \"scary\", \"suspicious\", \"watching\", \"monitoring\", \"gdpr\",\n",
        "        \"policy\", \"terms\", \"agreement\", \"encryption\", \"protected\", \"vulnerable\", \"hack\", \"risk\",\n",
        "        \"danger\", \"paranoid\", \"microphone\", \"camera\", \"recording\", \"personal\", \"information\", \"location\"\n",
        "    ],\n",
        "    \"Updates & Evolution\": [\n",
        "        \"update\", \"version\", \"bug\", \"feature\", \"release\", \"patch\", \"upgrade\", \"improve\",\n",
        "        \"improvement\", \"fix\", \"issue\", \"problem\", \"solved\", \"downgrade\", \"regression\", \"change\",\n",
        "        \"changed\", \"new\", \"added\", \"removed\", \"missing\", \"development\", \"roadmap\", \"progress\",\n",
        "        \"evolve\", \"evolution\", \"grow\", \"maturity\", \"mature\", \"immature\", \"beta\", \"alpha\", \"stable\"\n",
        "    ],\n",
        "    \"Support & Service\": [\n",
        "        \"support\", \"help\", \"service\", \"issue\", \"resolution\", \"customer\", \"contact\", \"call\",\n",
        "        \"phone\", \"email\", \"chat\", \"representative\", \"agent\", \"ticket\", \"case\", \"response\",\n",
        "        \"warranty\", \"replacement\", \"refund\", \"return\", \"satisfaction\", \"dissatisfaction\",\n",
        "        \"frustrated\", \"complaint\", \"feedback\", \"solve\", \"solution\", \"troubleshoot\", \"repair\"\n",
        "    ],\n",
        "    \"Social & Emotional Aspects\": [\n",
        "        \"personality\", \"character\", \"funny\", \"humor\", \"joke\", \"laugh\", \"fun\", \"entertaining\",\n",
        "        \"companion\", \"friend\", \"relationship\", \"emotion\", \"emotional\", \"human-like\", \"humanlike\",\n",
        "        \"personal\", \"personable\", \"warm\", \"cold\", \"robotic\", \"mechanical\", \"natural\", \"unnatural\",\n",
        "        \"conversation\", \"conversational\", \"chat\", \"talk\", \"dialogue\", \"interaction\", \"interactive\",\n",
        "        \"respond\", \"response\", \"reply\", \"engaging\", \"engage\", \"connection\", \"connect\", \"relate\"\n",
        "    ],\n",
        "    \"Personalization & Intelligence\": [\n",
        "        \"personalize\", \"customize\", \"preference\", \"learn\", \"adapt\", \"suggest\", \"recommendation\",\n",
        "        \"profile\", \"account\", \"user\", \"individual\", \"specific\", \"tailored\", \"custom\", \"habit\",\n",
        "        \"routine\", \"pattern\", \"predict\", \"predictive\", \"anticipate\", \"remember\", \"memory\",\n",
        "        \"context\", \"contextual\", \"awareness\", \"recognize\", \"familiar\", \"personal\", \"special\",\n",
        "        \"unique\", \"adjust\", \"adaptation\", \"history\", \"previous\", \"past\", \"experience\"\n",
        "    ]\n",
        "}\n",
        "print(\"\\nConfiguration and paths set.\")\n"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d7pOMrsOgMCu",
        "outputId": "c2db62f9-a00e-40b0-d72b-3c39f3028bb8"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "THESIS_ROOT on Drive set to: /content/drive/MyDrive/MyThesisProject\n",
            "Expecting input CSVs in: /content/drive/MyDrive/MyThesisProject/results\n",
            "Output directory for ABSA results: /content/drive/MyDrive/MyThesisProject/results/absa_full_results_colab\n",
            "Using GPU: Tesla T4\n",
            "\n",
            "Configuration and paths set.\n"
          ]
        }
      ]
    },
    {
      "source": [
        "#@title 3. Load Models & Prepare Keyword Matching Tools\n",
        "\n",
        "# --- Load spaCy for sentence splitting ---\n",
        "print(\"Loading spaCy model (en_core_web_sm)...\")\n",
        "try:\n",
        "    nlp_spacy = spacy.load(\"en_core_web_sm\")\n",
        "    # nlp_spacy.max_length = 1500000 # Uncomment and adjust if reviews are extremely long\n",
        "    print(\"spaCy model loaded.\")\n",
        "except OSError:\n",
        "    print(\"spaCy model 'en_core_web_sm' not found. Ensure it was installed in Cell 0.\")\n",
        "    raise\n",
        "\n",
        "# --- Prepare Keyword Matching Regex ---\n",
        "keyword_to_aspect_map = {}\n",
        "all_keywords_patterns = []\n",
        "for aspect_category, keywords in taxonomy.items():\n",
        "    for keyword in keywords:\n",
        "        kw_lower = keyword.lower() # Ensure keywords are lowercase for matching\n",
        "        keyword_to_aspect_map[kw_lower] = aspect_category\n",
        "        # Use word boundaries to match whole words only\n",
        "        all_keywords_patterns.append(r'\\b' + re.escape(kw_lower) + r'\\b')\n",
        "keyword_regex = re.compile('|'.join(all_keywords_patterns), re.IGNORECASE) # Case-insensitive matching\n",
        "print(\"Keyword regex compiled.\")\n",
        "\n",
        "# --- Load DeBERTa ABSA Model and Tokenizer ---\n",
        "# These will be loaded globally for use in the prediction function\n",
        "absa_tokenizer = None\n",
        "absa_model = None\n",
        "print(f\"Loading DeBERTa ABSA model: {MODEL_DEBERTA_ABSA}...\")\n",
        "try:\n",
        "    absa_tokenizer = AutoTokenizer.from_pretrained(MODEL_DEBERTA_ABSA)\n",
        "    absa_model = AutoModelForSequenceClassification.from_pretrained(MODEL_DEBERTA_ABSA).to(DEVICE)\n",
        "    absa_model.eval() # Set to evaluation mode (important for inference)\n",
        "    print(f\"DeBERTa ABSA model loaded successfully and moved to device: {DEVICE}\")\n",
        "except Exception as e:\n",
        "    print(f\"Error loading DeBERTa ABSA model: {e}\")\n",
        "    # If model loading fails, we cannot proceed.\n",
        "    raise"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FBhqFVmigfrm",
        "outputId": "078b8308-9832-4550-e8e4-30bbe49fa9f1"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading spaCy model (en_core_web_sm)...\n",
            "spaCy model loaded.\n",
            "Keyword regex compiled.\n",
            "Loading DeBERTa ABSA model: yangheng/deberta-v3-base-absa-v1.1...\n",
            "DeBERTa ABSA model loaded successfully and moved to device: cuda\n"
          ]
        }
      ]
    },
    {
      "source": [
        "#@title 4. Helper Functions (Memory Release & Sentiment Prediction)\n",
        "\n",
        "def release_memory(model_to_del=None, tokenizer_to_del=None, custom_message=\"\"):\n",
        "    \"\"\"Releases memory occupied by specified components and clears CUDA cache.\"\"\"\n",
        "    if model_to_del:\n",
        "        del model_to_del\n",
        "    if tokenizer_to_del:\n",
        "        del tokenizer_to_del\n",
        "    gc.collect() # Force garbage collection\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.empty_cache() # Clear PyTorch's CUDA memory cache\n",
        "    if custom_message:\n",
        "        print(custom_message)\n",
        "    # print(\"Memory release attempt complete.\")\n",
        "\n",
        "\n",
        "def predict_aspect_sentiment_batch(sentence_aspect_pairs, tokenizer, model, device_to_use, max_len, batch_size=32):\n",
        "    \"\"\"\n",
        "    Predicts sentiment for a batch of (sentence_text, aspect_category) pairs.\n",
        "    Returns a list of sentiment predictions.\n",
        "    \"\"\"\n",
        "    predictions = []\n",
        "    if not sentence_aspect_pairs:\n",
        "        return predictions\n",
        "\n",
        "    # Unzip the pairs\n",
        "    sentences, aspects = zip(*sentence_aspect_pairs)\n",
        "\n",
        "    try:\n",
        "        # Tokenize the batch\n",
        "        inputs = tokenizer(\n",
        "            list(sentences),  # Convert tuple to list for tokenizer\n",
        "            list(aspects),    # Convert tuple to list for tokenizer\n",
        "            truncation=True,\n",
        "            padding='max_length', # Pad to the longest sequence in the batch or max_length\n",
        "            max_length=max_len,\n",
        "            return_tensors='pt',\n",
        "            add_special_tokens=True\n",
        "        ).to(device_to_use)\n",
        "\n",
        "        with torch.no_grad(): # Disable gradient calculations for inference\n",
        "            outputs = model(**inputs)\n",
        "            logits = outputs.logits\n",
        "\n",
        "        predicted_class_ids = torch.argmax(logits, dim=-1).cpu().tolist() # Move to CPU before converting to list\n",
        "\n",
        "        for class_id in predicted_class_ids:\n",
        "            pred_sentiment = model.config.id2label[class_id].capitalize()\n",
        "            if pred_sentiment not in ['Positive', 'Negative', 'Neutral']:\n",
        "                predictions.append('Neutral') # Fallback for unexpected labels\n",
        "            else:\n",
        "                predictions.append(pred_sentiment)\n",
        "\n",
        "        return predictions\n",
        "\n",
        "    except Exception as e:\n",
        "        # print(f\"Error during batched sentiment prediction: {e}. Returning 'Error' for batch.\")\n",
        "        # If batch fails, return \"Error\" for each item in the batch\n",
        "        return [\"Error\"] * len(sentence_aspect_pairs)\n",
        "\n",
        "print(\"Helper functions defined.\")"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3PTUMu1BgnqL",
        "outputId": "6c4975d2-dc9b-43c8-c089-3ae4e130caec"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Helper functions defined.\n"
          ]
        }
      ]
    },
    {
      "source": [
        "#@title 5. Main Processing Loop (Full Scale ABSA)\n",
        "\n",
        "\n",
        "PREDICTION_PROCESSING_BATCH_SIZE = 64 if DEVICE.type == 'cuda' else 8\n",
        "\n",
        "\n",
        "for assistant in ASSISTANT_NAMES:\n",
        "    print(f\"\\n=================================================================\")\n",
        "    print(f\"Processing full dataset for: {assistant.upper()}\")\n",
        "    print(f\"=================================================================\")\n",
        "\n",
        "    input_file = input_dir / f\"{assistant}_with_topics.csv\"\n",
        "    output_file_path = output_dir / f\"{assistant}_full_absa_sentiments_colab.csv\"\n",
        "\n",
        "    if not input_file.exists():\n",
        "        print(f\"Input file not found for {assistant}: {input_file}. Skipping.\")\n",
        "        continue\n",
        "\n",
        "    try:\n",
        "        df_reviews_full = pd.read_csv(input_file)\n",
        "        print(f\"Loaded {len(df_reviews_full)} reviews for {assistant}.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading {input_file}: {e}. Skipping.\")\n",
        "        continue\n",
        "\n",
        "    # Validate required columns\n",
        "    required_cols = ['reviewId', 'clean_content', 'at']\n",
        "    if not all(col in df_reviews_full.columns for col in required_cols):\n",
        "        print(f\"One or more required columns ({', '.join(required_cols)}) missing in {input_file}. Skipping.\")\n",
        "        continue\n",
        "\n",
        "    df_reviews_full = df_reviews_full.dropna(subset=required_cols)\n",
        "    df_reviews_full['clean_content'] = df_reviews_full['clean_content'].astype(str)\n",
        "\n",
        "    # --- Subsetting Logic for Debugging or Full Run ---\n",
        "    if PROCESS_ALL_REVIEWS:\n",
        "        df_to_process = df_reviews_full.copy()\n",
        "        print(f\"Processing all {len(df_to_process)} reviews for {assistant}.\")\n",
        "    else:\n",
        "        if len(df_reviews_full) > NUM_REVIEWS_TO_PROCESS_DEBUG:\n",
        "            df_to_process = df_reviews_full.head(NUM_REVIEWS_TO_PROCESS_DEBUG).copy()\n",
        "            print(f\"DEBUG MODE: Processing a subset of {len(df_to_process)} reviews for {assistant}.\")\n",
        "        else:\n",
        "            df_to_process = df_reviews_full.copy()\n",
        "            print(f\"DEBUG MODE: Dataset for {assistant} has {len(df_to_process)} reviews (less than debug limit). Processing all available.\")\n",
        "    # --- End of Subsetting Logic ---\n",
        "\n",
        "    all_aspect_sentiments_data = [] # To store dictionaries for final DataFrame\n",
        "    sentence_aspect_pairs_batch = [] # To collect pairs for batch prediction\n",
        "    metadata_for_batch = [] # To store corresponding (reviewId, sentence, aspect, keyword, timestamp)\n",
        "\n",
        "    print(f\"Identifying aspects and preparing for sentiment prediction for {assistant}...\")\n",
        "    # Outer loop for reviews\n",
        "    for index, row in tqdm(df_to_process.iterrows(), total=len(df_to_process), desc=f\"Reviews ({assistant})\"):\n",
        "        review_id_val = row['reviewId']\n",
        "        review_text = row['clean_content']\n",
        "        review_timestamp = row['at']\n",
        "\n",
        "        if not review_text.strip():\n",
        "            continue\n",
        "\n",
        "        try:\n",
        "            review_text_for_spacy = review_text[:nlp_spacy.max_length] if len(review_text) > nlp_spacy.max_length else review_text\n",
        "            doc_spacy = nlp_spacy(review_text_for_spacy)\n",
        "\n",
        "            # Inner loop for sentences in a review\n",
        "            for sent in doc_spacy.sents:\n",
        "                sentence_text = sent.text.strip()\n",
        "                if len(sentence_text) < 10: # Skip very short sentences\n",
        "                    continue\n",
        "\n",
        "                found_keywords_in_sentence = keyword_regex.findall(sentence_text)\n",
        "                aspects_processed_for_this_sentence = set()\n",
        "\n",
        "                # Innermost loop for keywords in a sentence\n",
        "                for keyword in found_keywords_in_sentence:\n",
        "                    keyword_lower = keyword.lower()\n",
        "                    if keyword_lower in keyword_to_aspect_map:\n",
        "                        aspect_category = keyword_to_aspect_map[keyword_lower]\n",
        "\n",
        "                        if aspect_category not in aspects_processed_for_this_sentence:\n",
        "                            # Add to batch for prediction\n",
        "                            sentence_aspect_pairs_batch.append((sentence_text, aspect_category))\n",
        "                            metadata_for_batch.append({\n",
        "                                'reviewId': review_id_val,\n",
        "                                'sentence_text': sentence_text,\n",
        "                                'identified_aspect': aspect_category,\n",
        "                                'matched_keyword': keyword_lower,\n",
        "                                'timestamp': review_timestamp\n",
        "                            })\n",
        "                            aspects_processed_for_this_sentence.add(aspect_category)\n",
        "\n",
        "                            # If batch is full, predict and clear\n",
        "                            if len(sentence_aspect_pairs_batch) >= PREDICTION_PROCESSING_BATCH_SIZE:\n",
        "                                predicted_sentiments_batch = predict_aspect_sentiment_batch(\n",
        "                                    sentence_aspect_pairs_batch,\n",
        "                                    absa_tokenizer,\n",
        "                                    absa_model,\n",
        "                                    DEVICE,\n",
        "                                    MAX_SEQ_LENGTH,\n",
        "                                    batch_size=PREDICTION_PROCESSING_BATCH_SIZE # Pass configured batch size\n",
        "                                )\n",
        "                                # Combine metadata with predictions\n",
        "                                for i, meta_item in enumerate(metadata_for_batch):\n",
        "                                    meta_item['aspect_sentiment'] = predicted_sentiments_batch[i]\n",
        "                                    all_aspect_sentiments_data.append(meta_item)\n",
        "\n",
        "                                sentence_aspect_pairs_batch = [] # Clear batch\n",
        "                                metadata_for_batch = []      # Clear metadata\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Major error processing review ID {review_id_val}. Details: {e}. Skipping this review.\")\n",
        "            # Clear current batch if an error occurs at review level to avoid misalignment\n",
        "            sentence_aspect_pairs_batch = []\n",
        "            metadata_for_batch = []\n",
        "            continue\n",
        "\n",
        "    # Process any remaining items in the last batch\n",
        "    if sentence_aspect_pairs_batch:\n",
        "        predicted_sentiments_batch = predict_aspect_sentiment_batch(\n",
        "            sentence_aspect_pairs_batch,\n",
        "            absa_tokenizer,\n",
        "            absa_model,\n",
        "            DEVICE,\n",
        "            MAX_SEQ_LENGTH,\n",
        "            batch_size=PREDICTION_PROCESSING_BATCH_SIZE\n",
        "        )\n",
        "        for i, meta_item in enumerate(metadata_for_batch):\n",
        "            meta_item['aspect_sentiment'] = predicted_sentiments_batch[i]\n",
        "            all_aspect_sentiments_data.append(meta_item)\n",
        "\n",
        "    # --- Saving Results ---\n",
        "    if all_aspect_sentiments_data:\n",
        "        df_results = pd.DataFrame(all_aspect_sentiments_data)\n",
        "        print(f\"\\nSaving {len(df_results)} aspect-sentiment pairs for {assistant} to {output_file_path}...\")\n",
        "        try:\n",
        "            df_results.to_csv(output_file_path, index=False, encoding='utf-8')\n",
        "            print(f\"Saved successfully for {assistant}.\")\n",
        "            print(\"\\nSample of results:\")\n",
        "            print(df_results.head())\n",
        "        except Exception as e:\n",
        "            print(f\"Error saving results for {assistant} to CSV: {e}\")\n",
        "    else:\n",
        "        print(f\"No aspect-sentiment pairs found or generated for {assistant}.\")\n",
        "\n",
        "    # Optional: Release memory for the DataFrame if it's very large and you need RAM for the next assistant\n",
        "    if 'df_results' in locals():\n",
        "        del df_results\n",
        "    if 'df_to_process' in locals():\n",
        "        del df_to_process\n",
        "    if 'df_reviews_full' in locals():\n",
        "        del df_reviews_full\n",
        "    gc.collect()\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "\n",
        "print(\"\\n--- Full-scale ABSA processing complete for all specified assistants. ---\")"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 923,
          "referenced_widgets": [
            "e75e3bd4965b4f24aadf142c5ee26c40",
            "ad7bc95fe8ad48d48820b8fa8e2438b4",
            "aef8193ceafc466eb9dfc1e69661ef53",
            "acfb0f8da1c54f0b8c10964aa4257e57",
            "e76c243b53a44b82b9a041b83d1864ab",
            "75834512d23f470ba4b9fa690546ea9e",
            "800ce59a307d44cea5712e800c2cf978",
            "2c8fecb7831f4dafb9bff151e9300bbd",
            "06b9be7f0da44e398ec16c44eca51fd0",
            "414f94a7ea0241b4b5ac65f1a63df2c6",
            "f80f7e74779f4181beb4b83084add5aa",
            "06f9f42f6c7a4952967efa601bcf83a4",
            "6f1c3499ab324d38a88d67957ef05fb0",
            "1a1718ee954a43488892714b0a50aa80",
            "bcb0e2fb93c04ac68e94c5f7cefb906d",
            "9796f9aa81b349df83e98cb39117bff6",
            "7c7d072862954f8884a4ffb0c5405e45",
            "6c7ced9c42634f1481173bee320a2a85",
            "228d1bfc72634e65aaa96f1681e742cd",
            "d61f5cffd5154dd0a897f637c45fefd9",
            "236ec9f4284c47469bd141f262055f99",
            "7d6ec198c91b43828abcb72e258a4995"
          ]
        },
        "id": "3TqflN5Ugtyn",
        "outputId": "770b235d-2208-4db5-8abb-7c2784012259"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=================================================================\n",
            "Processing full dataset for: ALEXA\n",
            "=================================================================\n",
            "Loaded 141067 reviews for alexa.\n",
            "Processing all 141067 reviews for alexa.\n",
            "Identifying aspects and preparing for sentiment prediction for alexa...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e75e3bd4965b4f24aadf142c5ee26c40",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Reviews (alexa):   0%|          | 0/141067 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Saving 277313 aspect-sentiment pairs for alexa to /content/drive/MyDrive/MyThesisProject/results/absa_full_results_colab/alexa_full_absa_sentiments_colab.csv...\n",
            "Saved successfully for alexa.\n",
            "\n",
            "Sample of results:\n",
            "                               reviewId  \\\n",
            "0  ec6d4fdc-a343-4482-a68f-bb3640701560   \n",
            "1  edec9bb6-a3dd-4d84-8712-a987124e5836   \n",
            "2  e541aebf-83f4-4f14-828a-71d9643e15b8   \n",
            "3  e541aebf-83f4-4f14-828a-71d9643e15b8   \n",
            "4  33459b25-5c2e-41c2-8574-9ae74dae7e72   \n",
            "\n",
            "                                                                                                                                                                                  sentence_text  \\\n",
            "0                                                                                                           edit item shopping list ridiculously hard allow delete section lot easy delete word   \n",
            "1                                                                                                                                                                            good app reccomend   \n",
            "2                                                                                                                                                                      alexa prefer google home   \n",
            "3                                                                                                                                                                      alexa prefer google home   \n",
            "4  unintuitive app example multiroom music setting smart home multi room music feature difficult use like able switch multi room single room play app group device not app like terrible design   \n",
            "\n",
            "         identified_aspect matched_keyword            timestamp  \\\n",
            "0    Usability & Interface            easy  2017-10-01 03:40:48   \n",
            "1  Integration & Ecosystem             app  2017-10-01 06:10:53   \n",
            "2        Voice Recognition           alexa  2017-10-01 06:44:56   \n",
            "3  Integration & Ecosystem            home  2017-10-01 06:44:56   \n",
            "4  Integration & Ecosystem             app  2017-10-01 15:11:08   \n",
            "\n",
            "  aspect_sentiment  \n",
            "0         Negative  \n",
            "1         Positive  \n",
            "2          Neutral  \n",
            "3          Neutral  \n",
            "4         Negative  \n",
            "\n",
            "=================================================================\n",
            "Processing full dataset for: GOOGLE\n",
            "=================================================================\n",
            "Loaded 70252 reviews for google.\n",
            "Processing all 70252 reviews for google.\n",
            "Identifying aspects and preparing for sentiment prediction for google...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Reviews (google):   0%|          | 0/70252 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "06f9f42f6c7a4952967efa601bcf83a4"
            }
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "e75e3bd4965b4f24aadf142c5ee26c40": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ad7bc95fe8ad48d48820b8fa8e2438b4",
              "IPY_MODEL_aef8193ceafc466eb9dfc1e69661ef53",
              "IPY_MODEL_acfb0f8da1c54f0b8c10964aa4257e57"
            ],
            "layout": "IPY_MODEL_e76c243b53a44b82b9a041b83d1864ab"
          }
        },
        "ad7bc95fe8ad48d48820b8fa8e2438b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_75834512d23f470ba4b9fa690546ea9e",
            "placeholder": "​",
            "style": "IPY_MODEL_800ce59a307d44cea5712e800c2cf978",
            "value": "Reviews (alexa): 100%"
          }
        },
        "aef8193ceafc466eb9dfc1e69661ef53": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2c8fecb7831f4dafb9bff151e9300bbd",
            "max": 141067,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_06b9be7f0da44e398ec16c44eca51fd0",
            "value": 141067
          }
        },
        "acfb0f8da1c54f0b8c10964aa4257e57": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_414f94a7ea0241b4b5ac65f1a63df2c6",
            "placeholder": "​",
            "style": "IPY_MODEL_f80f7e74779f4181beb4b83084add5aa",
            "value": " 141067/141067 [3:44:47&lt;00:00,  6.96it/s]"
          }
        },
        "e76c243b53a44b82b9a041b83d1864ab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "75834512d23f470ba4b9fa690546ea9e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "800ce59a307d44cea5712e800c2cf978": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2c8fecb7831f4dafb9bff151e9300bbd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "06b9be7f0da44e398ec16c44eca51fd0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "414f94a7ea0241b4b5ac65f1a63df2c6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f80f7e74779f4181beb4b83084add5aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "06f9f42f6c7a4952967efa601bcf83a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6f1c3499ab324d38a88d67957ef05fb0",
              "IPY_MODEL_1a1718ee954a43488892714b0a50aa80",
              "IPY_MODEL_bcb0e2fb93c04ac68e94c5f7cefb906d"
            ],
            "layout": "IPY_MODEL_9796f9aa81b349df83e98cb39117bff6"
          }
        },
        "6f1c3499ab324d38a88d67957ef05fb0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7c7d072862954f8884a4ffb0c5405e45",
            "placeholder": "​",
            "style": "IPY_MODEL_6c7ced9c42634f1481173bee320a2a85",
            "value": "Reviews (google):  17%"
          }
        },
        "1a1718ee954a43488892714b0a50aa80": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_228d1bfc72634e65aaa96f1681e742cd",
            "max": 70252,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d61f5cffd5154dd0a897f637c45fefd9",
            "value": 11876
          }
        },
        "bcb0e2fb93c04ac68e94c5f7cefb906d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_236ec9f4284c47469bd141f262055f99",
            "placeholder": "​",
            "style": "IPY_MODEL_7d6ec198c91b43828abcb72e258a4995",
            "value": " 11876/70252 [15:39&lt;49:59, 19.46it/s]"
          }
        },
        "9796f9aa81b349df83e98cb39117bff6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7c7d072862954f8884a4ffb0c5405e45": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6c7ced9c42634f1481173bee320a2a85": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "228d1bfc72634e65aaa96f1681e742cd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d61f5cffd5154dd0a897f637c45fefd9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "236ec9f4284c47469bd141f262055f99": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7d6ec198c91b43828abcb72e258a4995": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}